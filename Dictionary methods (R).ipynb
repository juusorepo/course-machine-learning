{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary methods\n",
    "\n",
    "## Dataset for the exercise\n",
    "\n",
    "* [New York Times Comments](https://www.kaggle.com/aashita/nyt-comments/data), set of reders' comments for articles published in the New York Times\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "The comments allow a perspective to study what kind of concerns people raise when commenting to online articles.\n",
    "Study what seem to be the target of the commenting: New York Times staff or journalistic guidelines (suggesting that comments serveas a tool for journalists to interact with their audiences _or_ other audience members)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords <- c(\"New York Times\", \"NYT\")\n",
    "keywords <- tolower( keywords )\n",
    "keywords <- paste( keywords, collapse = '|' ) ## this is a reqular experssion trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path <- 'data/nyt-comments/'\n",
    "files <- list.files( path ) ## see all files in directory\n",
    "files <- files[ grepl(\"Comments\", files) ]\n",
    "files <- paste( path, files, sep = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"138467 comments mention any of these: new york times|nyt\"\n",
      "[1] \"There are in total 2176364\"\n"
     ]
    }
   ],
   "source": [
    "counter <- 0\n",
    "comments <- 0\n",
    "\n",
    "for( file in files ) {\n",
    "    \n",
    "    comments <- comments + nrow( data )\n",
    "    \n",
    "    data <- read.csv( file )\n",
    "    \n",
    "    data$commentBodyLower <- tolower( data$commentBody )\n",
    "    \n",
    "    counter <- counter + sum( str_detect( data$commentBodyLower , keywords ) )\n",
    "    \n",
    "}\n",
    "\n",
    "print( paste( counter, \"comments mention any of these:\", keywords ) )\n",
    "print( paste( \"There are in total\", comments ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Identify other potential keywords for this phenomena and add those keywords in the list.\n",
    "* Are there any cases where this approach might break? modify the code to mitigate them when possible\n",
    "* The data has `createDate` variable as well which identifies when the comment was created. Based on this, try to look for some temporal trends in comment counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language analysis\n",
    "\n",
    "In many languages, different words can have different forms. For example, 'I have an apple' and 'I have several apples' convey almost the same information, similarly 'She had an apple' and 'She has an apple' are almost identical. In Finnish language, such examples are much more extensive thanks to the many suffixes words may have several forms.\n",
    "\n",
    "![Joke about conjugation](https://i1.wp.com/finnishteacher.com/wp-content/uploads/2018/11/finnish-language-meme.png?resize=1024%2C591&ssl=1)\n",
    "\n",
    "This might make analysis difficult! Therefore often the language is **stemmed** or **lemmatized** into its basic form. Furthermore, tools such as [Natural Language Toolkit](https://www.nltk.org/) allow parsing text to identify proper nouns, identify named entities or determine if a word is adjective, noun etc.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Use same dataset.\n",
    "\n",
    "## Overarching research question\n",
    "\n",
    "Replicate the previous exercise using proper stemmatization. If results change, how and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " [1] \"this\"   \"is\"     \"a\"      \"longer\" \"exampl\" \"!\"      \"mani\"   \"word\"  \n",
      " [9] \"are\"    \"includ\" \"here\"   \",\"      \"and\"    \"we\"     \"shall\"  \"all\"   \n",
      "[17] \"word\"   \".\"     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = 'This is a longer example! Many words are included here, and we shall all words.'\n",
    "stemmed = text_tokens( message , stemmer = \"en\") \n",
    "    \n",
    "print( stemmed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
